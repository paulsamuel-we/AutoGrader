{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Assuming YOLOv8 is available as a module\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(r\"C:\\Users\\pauls\\OneDrive\\Desktop\\first_model.pt\")  # Replace with the correct path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = r\"C:\\Users\\pauls\\OneDrive\\Desktop\\OCR PROJECT\\images\"\n",
    "output_dir = r\"C:\\Users\\pauls\\OneDrive\\Desktop\\OCR PROJECT\\cropped\"\n",
    "classes = ['roll_no', 'grand_total', 'question']  # Define your class names\n",
    "\n",
    "# Create output directories for each class if they don't exist\n",
    "for class_name in classes:\n",
    "    os.makedirs(os.path.join(output_dir, class_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 grand_total, 15 questions, 1 roll_no, 183.6ms\n",
      "Speed: 7.0ms preprocess, 183.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x512 1 grand_total, 15 questions, 1 roll_no, 142.8ms\n",
      "Speed: 3.0ms preprocess, 142.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 grand_total, 15 questions, 1 roll_no, 159.6ms\n",
      "Speed: 2.9ms preprocess, 159.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 184.1ms\n",
      "Speed: 3.0ms preprocess, 184.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 156.3ms\n",
      "Speed: 4.0ms preprocess, 156.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 163.1ms\n",
      "Speed: 2.1ms preprocess, 163.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x640 1 grand_total, 15 questions, 1 roll_no, 252.2ms\n",
      "Speed: 3.7ms preprocess, 252.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 grand_total, 15 questions, 1 roll_no, 245.5ms\n",
      "Speed: 3.0ms preprocess, 245.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 grand_total, 9 questions, 1 roll_no, 255.3ms\n",
      "Speed: 3.9ms preprocess, 255.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 grand_total, 13 questions, 1 roll_no, 219.5ms\n",
      "Speed: 3.0ms preprocess, 219.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 274.0ms\n",
      "Speed: 3.0ms preprocess, 274.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x640 1 grand_total, 13 questions, 1 roll_no, 209.6ms\n",
      "Speed: 4.0ms preprocess, 209.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 235.6ms\n",
      "Speed: 4.0ms preprocess, 235.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 279.9ms\n",
      "Speed: 5.0ms preprocess, 279.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 252.0ms\n",
      "Speed: 7.1ms preprocess, 252.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 1 grand_total, 13 questions, 1 roll_no, 275.3ms\n",
      "Speed: 3.0ms preprocess, 275.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x640 1 grand_total, 15 questions, 1 roll_no, 191.5ms\n",
      "Speed: 4.0ms preprocess, 191.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 grand_total, 15 questions, 1 roll_no, 276.8ms\n",
      "Speed: 4.0ms preprocess, 276.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x512 1 grand_total, 13 questions, 1 roll_no, 226.0ms\n",
      "Speed: 3.0ms preprocess, 226.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 202.7ms\n",
      "Speed: 4.2ms preprocess, 202.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 271.5ms\n",
      "Speed: 8.0ms preprocess, 271.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 255.2ms\n",
      "Speed: 5.0ms preprocess, 255.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x640 1 grand_total, 15 questions, 1 roll_no, 274.9ms\n",
      "Speed: 5.0ms preprocess, 274.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 grand_total, 13 questions, 1 roll_no, 219.4ms\n",
      "Speed: 7.0ms preprocess, 219.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x640 1 grand_total, 13 questions, 1 roll_no, 295.7ms\n",
      "Speed: 6.0ms preprocess, 295.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 grand_total, 13 questions, 1 roll_no, 255.6ms\n",
      "Speed: 3.0ms preprocess, 255.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x640 1 grand_total, 13 questions, 1 roll_no, 254.4ms\n",
      "Speed: 5.6ms preprocess, 254.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 212.4ms\n",
      "Speed: 5.9ms preprocess, 212.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 200.4ms\n",
      "Speed: 3.5ms preprocess, 200.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 212.8ms\n",
      "Speed: 5.0ms preprocess, 212.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 206.2ms\n",
      "Speed: 3.0ms preprocess, 206.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 208.1ms\n",
      "Speed: 11.0ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 13 questions, 1 roll_no, 224.4ms\n",
      "Speed: 5.0ms preprocess, 224.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 242.5ms\n",
      "Speed: 12.0ms preprocess, 242.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 1 grand_total, 15 questions, 1 roll_no, 193.1ms\n",
      "Speed: 6.0ms preprocess, 193.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 189.6ms\n",
      "Speed: 4.0ms preprocess, 189.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 13 questions, 1 roll_no, 277.3ms\n",
      "Speed: 5.0ms preprocess, 277.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 1 grand_total, 15 questions, 1 roll_no, 197.0ms\n",
      "Speed: 3.0ms preprocess, 197.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x448 1 grand_total, 15 questions, 1 roll_no, 140.6ms\n",
      "Speed: 3.0ms preprocess, 140.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 203.4ms\n",
      "Speed: 3.0ms preprocess, 203.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 13 questions, 1 roll_no, 236.4ms\n",
      "Speed: 5.0ms preprocess, 236.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x448 1 grand_total, 15 questions, 1 roll_no, 206.4ms\n",
      "Speed: 4.0ms preprocess, 206.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 198.5ms\n",
      "Speed: 4.0ms preprocess, 198.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 13 questions, 1 roll_no, 260.6ms\n",
      "Speed: 4.0ms preprocess, 260.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 203.5ms\n",
      "Speed: 2.9ms preprocess, 203.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x448 1 grand_total, 15 questions, 1 roll_no, 204.3ms\n",
      "Speed: 3.0ms preprocess, 204.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 171.4ms\n",
      "Speed: 3.2ms preprocess, 171.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x448 10 questions, 1 roll_no, 145.9ms\n",
      "Speed: 2.9ms preprocess, 145.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 184.9ms\n",
      "Speed: 4.6ms preprocess, 184.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x640 1 grand_total, 9 questions, 1 roll_no, 234.6ms\n",
      "Speed: 4.0ms preprocess, 234.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 183.0ms\n",
      "Speed: 2.9ms preprocess, 183.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 221.6ms\n",
      "Speed: 3.2ms preprocess, 221.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 251.3ms\n",
      "Speed: 5.0ms preprocess, 251.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x640 1 grand_total, 15 questions, 1 roll_no, 283.6ms\n",
      "Speed: 4.0ms preprocess, 283.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 grand_total, 15 questions, 1 roll_no, 250.9ms\n",
      "Speed: 4.1ms preprocess, 250.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 221.4ms\n",
      "Speed: 5.0ms preprocess, 221.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x640 1 grand_total, 15 questions, 1 roll_no, 241.3ms\n",
      "Speed: 4.0ms preprocess, 241.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 grand_total, 13 questions, 1 roll_no, 247.6ms\n",
      "Speed: 4.0ms preprocess, 247.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 grand_total, 10 questions, 1 roll_no, 219.6ms\n",
      "Speed: 4.2ms preprocess, 219.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 13 questions, 1 roll_no, 252.3ms\n",
      "Speed: 3.0ms preprocess, 252.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 239.9ms\n",
      "Speed: 5.0ms preprocess, 239.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 13 questions, 1 roll_no, 261.7ms\n",
      "Speed: 6.0ms preprocess, 261.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x448 1 grand_total, 15 questions, 1 roll_no, 216.6ms\n",
      "Speed: 4.0ms preprocess, 216.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x480 1 grand_total, 14 questions, 1 roll_no, 191.1ms\n",
      "Speed: 5.0ms preprocess, 191.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 13 questions, 1 roll_no, 195.1ms\n",
      "Speed: 5.0ms preprocess, 195.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 225.5ms\n",
      "Speed: 4.0ms preprocess, 225.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x448 1 grand_total, 13 questions, 1 roll_no, 192.9ms\n",
      "Speed: 3.0ms preprocess, 192.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 198.8ms\n",
      "Speed: 3.9ms preprocess, 198.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 152.3ms\n",
      "Speed: 5.0ms preprocess, 152.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x448 1 grand_total, 15 questions, 1 roll_no, 208.1ms\n",
      "Speed: 2.9ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 254.6ms\n",
      "Speed: 7.0ms preprocess, 254.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 234.3ms\n",
      "Speed: 5.0ms preprocess, 234.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 163.1ms\n",
      "Speed: 4.0ms preprocess, 163.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 194.0ms\n",
      "Speed: 4.8ms preprocess, 194.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 204.9ms\n",
      "Speed: 5.0ms preprocess, 204.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 10 questions, 1 roll_no, 202.5ms\n",
      "Speed: 4.9ms preprocess, 202.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 181.4ms\n",
      "Speed: 4.9ms preprocess, 181.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 13 questions, 1 roll_no, 211.2ms\n",
      "Speed: 3.0ms preprocess, 211.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 245.7ms\n",
      "Speed: 6.0ms preprocess, 245.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 234.2ms\n",
      "Speed: 5.6ms preprocess, 234.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 245.1ms\n",
      "Speed: 6.0ms preprocess, 245.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 233.3ms\n",
      "Speed: 3.9ms preprocess, 233.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x448 1 grand_total, 15 questions, 1 roll_no, 232.2ms\n",
      "Speed: 4.0ms preprocess, 232.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 281.5ms\n",
      "Speed: 6.5ms preprocess, 281.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 231.6ms\n",
      "Speed: 4.9ms preprocess, 231.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 17 questions, 1 roll_no, 214.9ms\n",
      "Speed: 4.0ms preprocess, 214.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 237.6ms\n",
      "Speed: 2.9ms preprocess, 237.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 234.9ms\n",
      "Speed: 3.9ms preprocess, 234.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 1 grand_total, 15 questions, 1 roll_no, 217.3ms\n",
      "Speed: 8.0ms preprocess, 217.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 262.6ms\n",
      "Speed: 5.0ms preprocess, 262.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 1 grand_total, 15 questions, 1 roll_no, 210.6ms\n",
      "Speed: 3.0ms preprocess, 210.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 183.5ms\n",
      "Speed: 4.0ms preprocess, 183.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 232.7ms\n",
      "Speed: 3.0ms preprocess, 232.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 11 questions, 1 roll_no, 270.3ms\n",
      "Speed: 4.0ms preprocess, 270.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 183.7ms\n",
      "Speed: 5.0ms preprocess, 183.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 grand_total, 15 questions, 1 roll_no, 216.2ms\n",
      "Speed: 4.9ms preprocess, 216.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 1 grand_total, 15 questions, 1 roll_no, 252.4ms\n",
      "Speed: 4.9ms preprocess, 252.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 grand_total, 10 questions, 1 roll_no, 259.9ms\n",
      "Speed: 5.0ms preprocess, 259.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your custom YOLOv8 model\n",
    "model = YOLO(r\"C:\\Users\\pauls\\OneDrive\\Desktop\\OCR PROJECT\\first_model.pt\")  # Replace with the correct path\n",
    "\n",
    "# Define image directory and output directory\n",
    "image_dir = r\"C:\\Users\\pauls\\OneDrive\\Desktop\\OCR PROJECT\\dtst\"\n",
    "output_dir = r\"C:\\Users\\pauls\\OneDrive\\Desktop\\OCR PROJECT\\cropped\"\n",
    "\n",
    "# Create output directories for each class if they don't exist\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the main output directory\n",
    "\n",
    "# Process images\n",
    "for image_path in os.listdir(image_dir):\n",
    "    image_path = os.path.join(image_dir, image_path)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    results = model(image)[0]  # Run model inference\n",
    "\n",
    "    # Loop through all detected objects and save each\n",
    "    i = 0  # Counter for unique filenames\n",
    "    for detection in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = detection\n",
    "\n",
    "        # Create output directory for the specific class (if it doesn't exist)\n",
    "        class_name = model.names[int(class_id)]\n",
    "        class_output_dir = os.path.join(output_dir, class_name)\n",
    "        os.makedirs(class_output_dir, exist_ok=True)\n",
    "\n",
    "        # Crop the image\n",
    "        cropped_image = image[int(y1):int(y2), int(x1):int(x2)].copy()\n",
    "\n",
    "        # Generate unique filename with index\n",
    "        unique_filename = f\"{class_name}_{os.path.basename(image_path)}_{i}.jpg\"\n",
    "        i += 1  # Increment counter for each detection\n",
    "\n",
    "        output_path = os.path.join(class_output_dir, unique_filename)\n",
    "        cv2.imwrite(output_path, cropped_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
